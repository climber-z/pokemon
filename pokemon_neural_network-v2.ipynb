{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "ls1 = []\n",
    "ls2 = []\n",
    "for dirs in os.listdir('/kaggle/input/pokemon-generation-one/dataset/dataset/'):\n",
    "    ls1.append(dirs)\n",
    "    i = 0\n",
    "    for dir1 in os.listdir('/kaggle/input/pokemon-generation-one/dataset/dataset/' + dirs):\n",
    "        i += 1\n",
    "    ls2.append(i)\n",
    "# Any results you write to the current directory are saved as output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(ls1)\n",
    "print(ls2)\n",
    "print(len(ls1))\n",
    "print(len(ls2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#如何处理照片数据\n",
    "#搭建模型\n",
    "#训练\n",
    "#测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建训练集和测试集\n",
    "os.mkdir('/kaggle/input/train_data')\n",
    "os.mkdir('/kaggle/input/test_data')\n",
    "for dirs in os.listdir('/kaggle/input/pokemon-generation-one/dataset/dataset/'):\n",
    "    print(dirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(os.path.exists('/kaggle/input/train_data'))\n",
    "print(os.path.exists('/kaggle/input/test_data'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dir1 = '/kaggle/input/pokemon-generation-one/dataset/dataset'\n",
    "dir_train = '/kaggle/input/train_data'\n",
    "dir_test = '/kaggle/input/test_data'\n",
    "\n",
    "for dirs in os.listdir(dir1):\n",
    "    dir2 = dir1 + '/' + dirs\n",
    "    num = 0\n",
    "    for dirs1 in os.listdir(dir2):\n",
    "        num += 1\n",
    "    print(num)\n",
    "    \n",
    "    os.mkdir(dir_train + '/' + dirs)\n",
    "    os.mkdir(dir_test + '/' + dirs)\n",
    "    dir_train1 = dir_train + '/' + dirs\n",
    "    dir_test1 = dir_test + '/' + dirs\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for dirs2 in os.listdir(dir2):\n",
    "        dir3 = dir2 + '/' + dirs2\n",
    "        print(dir3)\n",
    "        \n",
    "        if i < 0.6 * num:\n",
    "            copyfile(dir3, (dir_train1 + '/' + dirs2))\n",
    "            i += 1\n",
    "            print(i)\n",
    "        else:\n",
    "            copyfile(dir3, (dir_test1 + '/' + dirs2))\n",
    "            i += 1\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dirs in os.listdir(dir_test):\n",
    "    print(dirs)\n",
    "\n",
    "for dirs in os.listdir(dir_train):\n",
    "    print(dirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 将多通道的图片变成单通道图片, 并统一像素\n",
    "def change_picture(dir_data, height, weight):\n",
    "    for dirs in os.listdir(dir_data):\n",
    "        dir1 = os.path.join(dir_data, dirs)\n",
    "        for dir2 in os.listdir(dir1):\n",
    "            dir3 = os.path.join(dir1, dir2)\n",
    "            if dir3[-3:] == 'jpg' or dir3[-3] == 'png':\n",
    "                img = Image.open(dir3)\n",
    "                gray = img.convert('L')\n",
    "                gray = gray.resize((height, weight))\n",
    "                gray.save(dir3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "change_picture(dir_train, 32, 32)\n",
    "change_picture(dir_test, 32, 32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# name and number dict\n",
    "name_number_pair = {}\n",
    "a = 0\n",
    "for dirs in os.listdir(dir_train):\n",
    "    if dirs not in name_number_pair:\n",
    "        name_number_pair[dirs] = a\n",
    "        a += 1\n",
    "\n",
    "print(name_number_pair)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a dict save the vector representation of the picutres\n",
    "# {number:[picture1: [height, weight], ...]}\n",
    "\n",
    "def treat_data(dir_data):\n",
    "    dic = dict()\n",
    "    for dirs in os.listdir(dir_data):\n",
    "        dir1 = os.path.join(dir_data, dirs)\n",
    "        ls = []\n",
    "        for dir2 in os.listdir(dir1):\n",
    "            dir3 = os.path.join(dir1, dir2)\n",
    "            if dir3[-3:] == 'jpg' or dir3[-3] == 'png':\n",
    "                img = Image.open(dir3)\n",
    "                img = np.array(img) / 255 # 归一\n",
    "                ls.append(img)\n",
    "\n",
    "        dic[dirs] = ls\n",
    "    return dic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "representation_train = treat_data(dir_train)\n",
    "representation_test =  treat_data(dir_test)\n",
    "\n",
    "small_train = dict()\n",
    "small_test = dict()\n",
    "\n",
    "# 通过修改i, j 修改训练的类别数\n",
    "i = 0\n",
    "for key, value in representation_train.items():\n",
    "    if i < 3:  # 修改3 修改类别数\n",
    "        small_train[key] = value\n",
    "        i += 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "j = 0\n",
    "for key, value in representation_test.items():\n",
    "    if j < 3:\n",
    "        small_test[key] = value\n",
    "        j += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(small_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sigmoid(x, alpha):\n",
    "    s_x = []\n",
    "    for i in range(len(x)):\n",
    "        if alpha * x[i] > -700:\n",
    "            s_x.append(1.0 / (1 + np.exp(-alpha * x[i])))\n",
    "        else:\n",
    "            s_x.append(np.exp(alpha * x[i]) / (1 + np.exp(alpha * x[i]))) # for result the problem of overflow encountered in exp\n",
    "\n",
    "    res_x = np.array(s_x)\n",
    "    return res_x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def softmax(x0,x):\n",
    "    ex = []\n",
    "    for i in range(len(x)):\n",
    "        ex.append(np.exp(x[i]))\n",
    "    return np.exp(x0)/sum(ex)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class model_NN:\n",
    "\n",
    "    def __init__(self, data_dict):\n",
    "        self.data_dict = data_dict\n",
    "        data_class_total_arr = []\n",
    "        n = 0\n",
    "        \n",
    "        for item in self.data_dict:\n",
    "            data_class_total_arr.append(self.data_dict[item])\n",
    "\n",
    "        data_class_total_list = []\n",
    "\n",
    "        for data_class_idem_arr in data_class_total_arr:\n",
    "            data_class_idem_list = []\n",
    "            for image0 in data_class_idem_arr:\n",
    "                image0 = image0.tolist()  # 2-dimension list for each image\n",
    "                image = []\n",
    "                n = n + 1\n",
    "                for line in image0:\n",
    "                    for unit in line:\n",
    "                        image.append(unit)  # 1-dimension list for each image\n",
    "                # print(image)\n",
    "                data_class_idem_list.append(np.array(image))\n",
    "            data_class_total_list.append(data_class_idem_list)\n",
    "\n",
    "        self.data_total_extend = data_class_total_list\n",
    "        # invert all data to a total list which includes lists of classed-images, and the image is a 1-dimension array\n",
    "\n",
    "        first_class = self.data_total_extend[0]\n",
    "        # first class of images in total list\n",
    "\n",
    "        self.image_dim = len(first_class[0])\n",
    "        self.image_num = n\n",
    "\n",
    "\n",
    "    def forward_propagation(self, sigmoid_alpha, label_index, image, weight_list):\n",
    "        # num_layer=1  !!!Attention: layer_dim should be bigger than 1\n",
    "        # val_error_total = 0\n",
    "\n",
    "        # temps = self.data_total_extend[label_index]\n",
    "        # image = temps[image_index]\n",
    "\n",
    "        x0 = image\n",
    "        print('x0',x0)\n",
    "        #x0_act = sigmoid(x0, sigmoid_alpha)\n",
    "        w0 = weight_list[0]\n",
    "        print('w0',w0)\n",
    "        #w0 = np.random.rand(layer_dim, self.image_dim)\n",
    "\n",
    "        x1 = np.matmul(w0, x0)\n",
    "        print('x1',x1)\n",
    "        x1_act = sigmoid(x1, sigmoid_alpha)\n",
    "        print('x1_act',x1_act)\n",
    "        w1 = weight_list[1]\n",
    "        #w1 = np.random.rand(len(self.data_total_extend), layer_dim)\n",
    "\n",
    "        x_out = np.matmul(w1, x1_act)\n",
    "        print('x_out',x_out)\n",
    "        #x_out_act = sigmoid(x_out, sigmoid_alpha)\n",
    "        x_out_act_list = []\n",
    "        for m in range(len(x_out)):\n",
    "            x_out_act_list.append(softmax(x_out[m],x_out))\n",
    "        x_out_act = np.array(x_out_act_list)\n",
    "        print('x_out_act', x_out_act)\n",
    "\n",
    "        standard_list = []\n",
    "        for i in range(len(x_out_act)):\n",
    "            if i == label_index:\n",
    "                standard_list.append(1)\n",
    "            else:\n",
    "                standard_list.append(0)\n",
    "        standard = np.array(standard_list)\n",
    "\n",
    "        val_error_list = []\n",
    "        #val_error_abs_list =[]\n",
    "        val_error = 0\n",
    "        for i in range(len(x_out_act)):\n",
    "            val_error_list.append(x_out_act[i] - standard[i])\n",
    "            # val_error_abs_list.append(abs(val_error_list[i]))\n",
    "            val_error += val_error_list[i] ** 2  # calculation of error value for each image\n",
    "        # print(val_error)\n",
    "        # val_error_total += val_error\n",
    "        x_out_list = x_out.tolist()\n",
    "        res_class = x_out_list.index(max(x_out_list)) # give the result of class\n",
    "\n",
    "        x_vect_list = [x0, x1, x_out]\n",
    "        x_act_vect_list = [x1_act, x_out_act]\n",
    "\n",
    "        result = [x_vect_list, x_act_vect_list, standard, val_error,res_class]\n",
    "        return result\n",
    "\n",
    "    def backward_prograpation(self, x_vect_list, x_act_vect_list, standard, sigmoid_alpha, weight_list):\n",
    "\n",
    "        x0 = x_vect_list[0]\n",
    "        x1 = x_vect_list[1]\n",
    "        x_out = x_vect_list[2]\n",
    "        #x0_act = x_act_vect_list[0]\n",
    "        x1_act = x_act_vect_list[0]\n",
    "        x_out_act = x_act_vect_list[1]\n",
    "\n",
    "        Dx_out_act = -2 * (standard - x_out_act)\n",
    "        \n",
    "        Dx_out_act_xout = []\n",
    "        sum = 0\n",
    "        for i in range(len(x_out)):\n",
    "            sum += np.exp(x_out[i])\n",
    "        for i in range(len(x_out)):\n",
    "            A = sum - np.exp(x_out[i])\n",
    "            Dx_out_act_xout.append(softmax(x_out[i],x_out)* A /(np.exp(x_out[i]) + A))\n",
    "            \n",
    "        Dx_out_act_to_x_out = np.array(Dx_out_act_xout)           \n",
    "        # Dx_out_act_to_x_out = sigmoid_alpha * np.exp(-sigmoid_alpha * x_out) / ((1 + np.exp(-sigmoid_alpha * x_out)) ** 2)\n",
    "        Dx_out = Dx_out_act * Dx_out_act_to_x_out\n",
    "        Dw1 = np.multiply(Dx_out.reshape(-1, 1), x1_act)\n",
    "\n",
    "        # Dx_out_to_x_1_act = w1\n",
    "        Dx1_act_to_x1 = sigmoid_alpha * np.exp(-sigmoid_alpha * x1) / ((1 + np.exp(-sigmoid_alpha * x1)) ** 2)\n",
    "        # Dw0 = np.multiply((Dx_out * Dx1_act_to_x1).reshape(-1, 1), x0_act)\n",
    "        w1 = weight_list[1]\n",
    "        # Dw0 = Dw0 * w1\n",
    "        mid = (np.matmul(Dx_out, w1) * Dx1_act_to_x1)\n",
    "        Dw0 = np.multiply(mid.reshape(-1, 1), x0)\n",
    "\n",
    "        grad_list = [Dw0, Dw1]\n",
    "\n",
    "        return grad_list\n",
    "\n",
    "    def gradient_pas_fixe(self, pas, para_matrix_list, grad_matrix_list):\n",
    "        para_new_list = []\n",
    "\n",
    "        for i in range(len(para_matrix_list)):\n",
    "            para_matrix = para_matrix_list[i]\n",
    "            grad_matrix = grad_matrix_list[i]\n",
    "            para_new = para_matrix - pas * grad_matrix\n",
    "            para_new_list.append(para_new)\n",
    "\n",
    "        return para_new_list\n",
    "\n",
    "\n",
    "    def train(self, sigmoid_alpha, layer_dim, pas, precision):\n",
    "        sig_a = sigmoid_alpha\n",
    "        p = pas\n",
    "        eps = precision * self.image_num\n",
    "        iteration = 0\n",
    "        #w_storage_image = []\n",
    "        #w_storage_class = []\n",
    "        error = 0\n",
    "\n",
    "        while (error > eps) or (iteration == 0):\n",
    "            error = 0\n",
    "            for label_i in (range(len(self.data_total_extend))):\n",
    "             #   if iteration != 0:\n",
    "              #      weight_list_mid = w_storage_class[label_i]\n",
    "\n",
    "                #w_storage_image = []\n",
    "\n",
    "                for image_i in range(len(self.data_total_extend[label_i])):\n",
    "\n",
    "                    image_mid = self.data_total_extend[label_i]\n",
    "                    image = image_mid[image_i]\n",
    "\n",
    "                    if iteration == 0 and label_i == 0 and image_i == 0:\n",
    "                        weight_list = [-1 + 2 * np.random.rand(layer_dim, self.image_dim), -1 + 2 * np.random.rand(len(self.data_total_extend), layer_dim)]\n",
    "\n",
    "                    forward_result = self.forward_propagation(sig_a, label_i, image, weight_list)\n",
    "                    error_temp = forward_result[3]\n",
    "                    grad_list = self.backward_prograpation(forward_result[0], forward_result[1], forward_result[2], sig_a, weight_list)\n",
    "                    weight_list = self.gradient_pas_fixe(p, weight_list, grad_list)\n",
    "\n",
    "                    error += error_temp\n",
    "                    #w_storage_image.append(weight_list)\n",
    "\n",
    "                #w_storage_class.append(w_storage_image)\n",
    "            print(\"The iteration time is:\",iteration)\n",
    "            iteration += 1\n",
    "\n",
    "        w_trained = weight_list\n",
    "        return w_trained\n",
    "\n",
    "\n",
    "    def predict(self, sigmoid_alpha, data_test_dict, w_trained):\n",
    "\n",
    "        sig_a = sigmoid_alpha\n",
    "        data_test_extend = []\n",
    "        data_mid = []\n",
    "        error_list = []\n",
    "        result_class_list = []\n",
    "\n",
    "        for item in data_test_dict:\n",
    "            data_mid.append(data_test_dict[item])      # 把所有类的数据都放在同一个列表里，每个类的列表里都有多张图片，图片是以二维数组的形式存在\n",
    "\n",
    "        for label_mid in data_mid:\n",
    "            label = []\n",
    "            for image2 in label_mid:\n",
    "                image2 = image2.tolist()  # 2-dimension list for each image\n",
    "                image1 = []\n",
    "                for line in image2:\n",
    "                    for unit in line:\n",
    "                        image1.append(unit)  # 1-dimension list for each image\n",
    "                # print(image)\n",
    "                label.append(np.array(image1))\n",
    "            data_test_extend.append(label)     # data_test_extend 将所有图片变成一维\n",
    "\n",
    "\n",
    "        for label_i in range(len(data_test_extend)):\n",
    "\n",
    "            error_list_mid = []\n",
    "            result_class_list_mid = []\n",
    "\n",
    "            for image_i in range(len(data_test_extend[label_i])):\n",
    "\n",
    "                image_mid = data_test_extend[label_i]\n",
    "                image = image_mid[image_i]\n",
    "                #weight_list_mid = w_trained[label_i]\n",
    "                weight_list = w_trained\n",
    "                forward_result = self.forward_propagation(sig_a, label_i, image, weight_list)\n",
    "                error = forward_result[3]\n",
    "                result_class = forward_result[4]\n",
    "                error_list_mid.append(error)\n",
    "                result_class_list_mid.append(result_class)\n",
    "                \n",
    "\n",
    "            error_list.append(error_list_mid)\n",
    "            result_class_list.append(result_class_list_mid)\n",
    "\n",
    "        result = error_list\n",
    "        # val_result = 0\n",
    "        right_cnt = 0\n",
    "\n",
    "        for l in range(len(error_list)):\n",
    "            print (\"For class\",l,\"'s imgages :\\n\")\n",
    "            for i in range(len(error_list[l])):\n",
    "                mid = result_class_list[l]\n",
    "                mid1 = error_list[l]\n",
    "                print (\"    image\",i,\":     result of class is:\",mid[i],\"   error is:\",mid1[i],'\\n')\n",
    "                \n",
    "                if mid[i] == l:\n",
    "                    right_cnt += 1\n",
    "        \n",
    "        val_result = right_cnt/self.image_num\n",
    "        \n",
    "        \n",
    "        print ('\\n\\nThe result of precision is:',val_result)\n",
    "        print (\"\\n-----------------------------------------Program FINISHED-------------------------------------------\")\n",
    "\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Train = model_NN(small_train)\n",
    "Test = model_NN(small_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#################################CHANGE Parameters######################################################################\n",
    "sigmoid_alpha = 1\n",
    "layer_dim = 128\n",
    "# Attention: layer dimension should be bigger than 1, because the error will be caused with layer_dim = 1\n",
    "precision = 0.1 # change precision here!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"\\n-------------------------------------------Program START--------------------------------------------\")\n",
    "print(\"With the coefficient of sigmoid function is:\", sigmoid_alpha,'\\n')\n",
    "\n",
    "\n",
    "#weight_list = [np.random.rand(layer_dim, x.image_dim), np.random.rand(len(x.data_total_extend), layer_dim)\n",
    "\n",
    "print(\"---------------------------------------------TRAINING----------------------------------------------\\n\\n\")\n",
    "w = Train.train(sigmoid_alpha, layer_dim, 0.2, precision) \n",
    "print(\"---------------------------------------The Result of train---------------------------------------\\n\")\n",
    "print(\"Weight matrix are: \")\n",
    "print(w)\n",
    "\n",
    "print(\"\\n---------------------------------------The Result of Predict---------------------------------------\\n\")\n",
    "print(\"with precision of\", precision)\n",
    "Test.predict(sigmoid_alpha, small_test, w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}